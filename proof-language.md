---
geometry: margin=2cm
---

\newcommand{\limplies}{\to}
\renewcommand{\phi}{\varphi}


Matching logic proof format
===========================

This is a proposed matching logic proof format.

## Relation to Metamath

Note that this language heavily based on the metamath format for compressed proofs.
Besides being a binary rather than ASCII encoding, there are two major changes.

1.  We use the same mechanism for constructing terms and proofs, allowing better
    compression.
2.  We allow emmitting multiple proofs from the same representation. This allows
    us to represent lemmas and compression uniformly.
    That is, we can store the entire contents of a single metamath file in this format,
    rather than just the proof of a single lemma.

## Relation to postfix notation/RPN

The format may be viewed as a generalization
of postfix notation (incidentally also called Lukaseiwicz notation),
for an expression computing the conclusion of a proof.

We also allow marking subexpressions (i.e.Â either proofs or patterns) for reuse. This
allows us to represent lemmas, and compactly representing configurations and notation.

(This needs input from ZK folk.) Finally, we allow marking constructed proofs
as public. This serves two purposes. First, it allows us to publish lemmas
that may be reused in other proofs. Second, it allows us to publish the main
result proved by the proof.


## As a stack machine

It may also be viewed language interpreted using a stack machine.
This stack machines constructs terms---either patterns or proofs. We treat
patterns and proofs uniformly---at an abstract level, they are both terms we
must construct, with particular well-formedness criteria. It is intended for the
most part, that **the verifier only needs to keep proved conclusions in
memory**.


## Goals:

-   No upfront parsing cost.
-   Easily verifiable using ZK
-   Low memory usage.
-   Composability


## Non-goals:

-   Parallization: I have not been thinking explicitly about parallel verification of this format,
    because I expect parallization to happen by composing units of this format into larger proofs.
    Even so I think with some additional metadata, we could make
    this format parallizable.

-   Human readability: We aim to be a simple binary format. To become human
    readable, we expect the user to run a secondary program to pretty-print the
    proof. Note that symbols, lemmas, and notation do not have names.


Terms
=====

As mentioned previously, we may view this format as a language for constructing
terms that meet particular well-formedness criteria. Let us first enumerate
those terms, in a python-esque pseudocode.

`Term`s are of two types, `Pattern`, and `Proof`.
Every `Term` has a well-formedness check.
Every `Proof` has a conclusion.

```python
abstract class Term:
    abstract def well_formed:
        ...

abstract class Pattern(Term):
    def well_formed():
        # Fails if any two MetaVars with the same id has
        # different meta-requirements
        # MetaVars are introduced later.
    ...

abstract class Proof:
    abstract def conclusion:
        ...
```

`Pattern`s
----------

There are two classes of `Pattern`,
the expected concrete constructors for matching logic patterns,
and a representation for various "meta" patterns.

### Standard patterns

```python
class Symbol(Pattern)
    name: uint32

class SVar(Pattern)
    name: uint32

class EVar(Pattern)
    name: uint32

class Implication(Pattern)
    left: Pattern
    right: Pattern

class Application(Pattern)
    left: Pattern
    right: Pattern

class Exists(Pattern)
    var: EVar
    subpattern : Pattern

class Mu(Pattern)
    var: SVar
    subpattern : Pattern

    def well_formed():
        return super.well_formed()
           and subpattern.var_occurs_positively(var)
```

### Meta-patterns

Meta-patterns allow us to represent axiom- and theorem-schemas through the use
of metavariables:

```python
class MetaVar : Pattern
    name: uint32

    # Meta-requirements that must be satisfied by any instantiation.
    fresh: list[EVar | SVar]        # variables that must not occur in an instatiation
    positive: list[SVar]            # variables that must only occur positively in an instatiation
    negative: list[SVar]            # variables that must only occur negatively in an instatiation
    application_context: list[EVar] # Variables that must only occur as a hole variable in an application context.
```

Each `MetaVar` has a list of requirements that must be met by any instantiation.
These may also be used by the well-formedness checks for `Proof`s.

We also need to represent substitutions applied to `MetaVar`s.

```python
class ESubst : Pattern
    pattern: MetaVar
    var: EVar
    plug: Pattern

class SSubst : Pattern 
    pattern: MetaVar
    var: SVar
    plug: Pattern
```


`Proof`s
--------

### Axiom Schemas

Axiom schemas are `Proof`s that do not need any input arguments.
They may use `MetaVar`s to represent their schematic nature.

```python
class Lukaseiwicz : Proof
    def conclusion():
        phi1 = MetaVar('phi1')
        return Implication(Implication(Implication(MetaVar(phi1) , ...)...)...)

class Quantifier : Proof
    def conclusion():
        x = EVar('#x')
        y = EVar('#y')
        phi = MetaVar('phi', fresh=[y])
        return Implication(ESubst(phi, x, y), Exists(x, phi))

class PropagationOr : Proof
    def conclusion():
        hole = EVar('#hole')
        C = MetaVar(application_context=(EVar('#hole'),))
        phi1 = MetaVar('#phi1')
        phi2 = MetaVar('#phi2')
        return Implication(ESubst(C, or(phi1, phi2), hole), or(ESubst(C, phi1, hole), ESubst(C, phi2, hole)))

...
```


### Meta Inference rule

Using a single rule of meta inference, we may instantiate metavariables.
Note that we do not need to instantiate metavariables immediately.
This allows us to prove theorem schemas, such as $\phi \limplies \phi$.

```python
class InstantiateSchema : Proof
    subproof : Proof
    metavar: MetaVar
    instantiation: Pattern

    def well_formed():
        # Fails if the instantiation does not meet the
        # disjoint/positive/freshness/application ctx
        # criterea of the metavar.

    def conclusion():
        return subproof.meta_substitute(metavar, instantiation)
```

### Ordinary inference

```python
class ModusPonens: Proof
    premise_left: Implication
    premise_right: Pattern

    def conclusion():
        return premise_left.right

class Generalization: Proof
    premise: Implication

    def phi1():
        premise.left
    def phi2():
        premise.right

    def conclusion():
        return Implication(ESubst(MetaVar(phi), EVar(x), EVar(y)), Exists(EVar(x), MetaVar(phi)))

    def well_formed():
        EVar(x) is fresh in phi1()
...
```

Instructions and semantics
==========================

Each of these instructions checks that the constructed `Term` is well-formed before pushing onto the stack.
Otherwise, execution aborts, and verification fails.

*   Supporting:

    `List n:uint32`
    : Consume $n$ items from the stack, and push a list containing those items to the stack.

* Variables and Symbols:

    `EVar <uint32>`
    : Push an `EVar` onto the stack.

    `SVar <uint32>`
    : `Push an `SVar` onto the stack.

    `Symbol <uint32>`
    : `Push an `Symbol` onto the stack.

    `MetaVar <uint32>`
    : Consume the first four entries from the stack (corresponding to the meta-requirements),
      and push an `MetaVar` onto the stack.

* Connectives:

    `Implication`/`Application`/`Exists`/`Mu`
    : Consume the first two patterns from the stack, and push an implication/application/exists/mu onto the stack with appropriate argumetns.

* Axiom Schemas

    `Lukaseiwicz`/`Quantifier`/`PropagationOr`/`PropagationExists`/`PreFixpoint`/`Existance`/`Singleton`
    : Push Proof term corresponding to axiom schema onto the stack.

* Meta inference

    `InstantiateSchema`
    : Consume a `Proof`, `MetaVar` and `Pattern` off the stack, and push the instantiated proof term to the stack.

*   Inference rules

    `ModusPonens`/`Generalization`/`Frame`/`Substitution`/`KnasterTarski`
    : Consume one or two `Proof` terms off the stack and push the new proof term.

*   Memory manipulation:

    `Save`
    : Store the top of the stack to the lowest unused index in memory.

    `Load i:uint32`
    : Push the `Term` at index $i$ to the top of the stack.

    `Delete i:uint32`
    : Remove the `Term` at index $i$ from memory. This is not strictly needed,
      but will allow the verifier to use less memory. The memory slot is not considered free.

*   Journal manipulation.

    `Publish`
    : publish the entry at the top of the stack to the journal.

*   Stack manipulation.

    `Pop`
    : Consume the top of the stack. (Do we need this? Probably not.)

Verification
============

The verifier takes two inputs[^1]:

1.  `theory` A file with instructions to construct patterns corresponding to the
    theory $\Gamma$. This is public.
2.  `lemmas`: A file with instructions to construct patterns corresponding the
    lemmas previously proved in other proof files. An aggregation curcuit will
    need to check that the theory used by that proof is a subset of the theory
    for the corrent proof.
3.  `proof`: A file with instructions to construct proofs about the theory. This
    file is private, and should be rolled-up by ZK.

The verifier consumes the theory file. The stack should now only include `Pattern` terms.
These are moved into the initial entries of the memory, as `Proof` terms.
The verifier then consumes the `proof` file and produces a "journal"[^2],
containing a list of instructions to construct the patterns of theorems proved.

[^1]: This needs input from the ZK folk for the exact input mechanism.
[^2]: Using Risc Zero terminology

The verifier state consists of a stack of `Term`s, and
an indexed list of saved `Term`s, called the memory.

Composition
===========

We may compose proofs together, by allowing proofs to reuse results contained in another proofs journal.
A subset of the contents of the journal of one proof
may be included in the input file of the other **so long as **

Notation and Lemmas
===================

Lemmas are represented as meta-theorems---theorems that use metavariables.
Through the `Save` instruction its proof can be reused multiple times and with different instantiations of metavaraibles.

Notation is handled using set variables the `Substitution` proof rule.
